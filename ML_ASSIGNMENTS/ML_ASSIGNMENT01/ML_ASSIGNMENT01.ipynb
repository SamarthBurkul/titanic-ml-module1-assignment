{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy import stats\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"CALIFORNIA HOUSING PRICE PREDICTION - REGRESSION ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 0: dataset path check\n",
        "# ---------------------------\n",
        "DATA_PATH = '/content/housing.csv'  # in Colab upload to /content/ or change path\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}. Upload housing.csv to this path.\")\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 1: Load & Inspect\n",
        "# ---------------------------\n",
        "df_raw = pd.read_csv(DATA_PATH)\n",
        "df = df_raw.copy() # Use df for processing to keep df_raw pristine\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(df.head(3))\n",
        "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Target stats\n",
        "print(\"\\nTarget (median_house_value) stats:\")\n",
        "print(df['median_house_value'].describe())\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 2: EDA (brief; plots saved)\n",
        "# ---------------------------\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "# Target histogram\n",
        "plt.figure()\n",
        "df['median_house_value'].hist(bins=50)\n",
        "plt.title('Median House Value Distribution')\n",
        "plt.xlabel('Median House Value ($)')\n",
        "plt.ylabel('Count')\n",
        "plt.savefig('outputs/housing_target_dist.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Geographic scatter colored by target\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(df['longitude'], df['latitude'], c=df['median_house_value'], cmap='viridis', s=8, alpha=0.4)\n",
        "plt.colorbar(label='House Value')\n",
        "plt.title('Geographic plot')\n",
        "plt.savefig('outputs/geographic.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Correlation heatmap of numeric features\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(df[num_cols].corr(), annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.savefig('outputs/corr_matrix.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "print(\"EDA plots saved to /content/outputs/\")\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 3: Preprocessing & Features\n",
        "# ---------------------------\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Missing values\n",
        "if df_processed['total_bedrooms'].isnull().sum() > 0:\n",
        "    df_processed['total_bedrooms'].fillna(df_processed['total_bedrooms'].median(), inplace=True)\n",
        "\n",
        "# Feature engineering\n",
        "df_processed['rooms_per_household'] = df_processed['total_rooms'] / df_processed['households']\n",
        "df_processed['bedrooms_per_room'] = df_processed['total_bedrooms'] / df_processed['total_rooms']\n",
        "df_processed['population_per_household'] = df_processed['population'] / df_processed['households']\n",
        "df_processed['log_median_income'] = np.log1p(df_processed['median_income'])\n",
        "df_processed['log_population'] = np.log1p(df_processed['population'])\n",
        "\n",
        "# Clip engineered extremes (practical)\n",
        "df_processed['rooms_per_household'] = df_processed['rooms_per_household'].clip(upper=50)\n",
        "df_processed['population_per_household'] = df_processed['population_per_household'].clip(upper=50)\n",
        "\n",
        "# One-hot encode ocean_proximity\n",
        "df_encoded = pd.get_dummies(df_processed, columns=['ocean_proximity'], prefix='ocean')\n",
        "\n",
        "# Drop any non-numeric leftovers (none expected)\n",
        "X = df_encoded.drop('median_house_value', axis=1).select_dtypes(include=[np.number])\n",
        "y = df_encoded['median_house_value']\n",
        "\n",
        "print(\"Final feature matrix shape:\", X.shape)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 4: Models & evaluation\n",
        "# ---------------------------\n",
        "def evaluate_model(model, X_tr, X_te, y_tr, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_tr_pred = model.predict(X_tr)\n",
        "    y_te_pred = model.predict(X_te)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_te, y_te_pred))\n",
        "    test_mae = mean_absolute_error(y_te, y_te_pred)\n",
        "    train_r2 = r2_score(y_tr, y_tr_pred)\n",
        "    test_r2 = r2_score(y_te, y_te_pred)\n",
        "    return {\n",
        "        'Train_RMSE': train_rmse,\n",
        "        'Test_RMSE': test_rmse,\n",
        "        'Test_MAE': test_mae,\n",
        "        'Train_R2': train_r2,\n",
        "        'Test_R2': test_r2\n",
        "    }, model\n",
        "\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'Ridge_a1': Ridge(alpha=1.0, random_state=42),\n",
        "    'Lasso_a1': Lasso(alpha=1.0, random_state=42),\n",
        "    'DecisionTree_d5': DecisionTreeRegressor(max_depth=5, random_state=42),\n",
        "    'DecisionTree_d10': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
        "    'DecisionTree_full': DecisionTreeRegressor(random_state=42),\n",
        "    'RandomForest_100': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
        "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "trained = {}\n",
        "for name, m in models.items():\n",
        "    print(\"Training:\", name)\n",
        "    res, trained_model = evaluate_model(m, X_train_scaled, X_test_scaled, y_train, y_test)\n",
        "    res['Model'] = name\n",
        "    results.append(res)\n",
        "    trained[name] = trained_model\n",
        "    print(f\"  Train RMSE: ${res['Train_RMSE']:.2f}, Test RMSE: ${res['Test_RMSE']:.2f}, Test MAE: ${res['Test_MAE']:.2f}\")\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values('Test_RMSE')\n",
        "results_df.to_csv('outputs/model_comparison.csv', index=False)\n",
        "print(\"Model comparison saved to outputs/model_comparison.csv\")\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 5: Bias-Variance (Decision Tree depth sweep)\n",
        "# ---------------------------\n",
        "depths = list(range(1, 21))\n",
        "train_rmse_list, test_rmse_list = [], []\n",
        "for d in depths:\n",
        "    dt = DecisionTreeRegressor(max_depth=d, random_state=42)\n",
        "    dt.fit(X_train_scaled, y_train)\n",
        "    train_rmse_list.append(np.sqrt(mean_squared_error(y_train, dt.predict(X_train_scaled))))\n",
        "    test_rmse_list.append(np.sqrt(mean_squared_error(y_test, dt.predict(X_test_scaled))))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(depths, train_rmse_list, marker='o', label='Train RMSE')\n",
        "plt.plot(depths, test_rmse_list, marker='s', label='Test RMSE')\n",
        "plt.xlabel('Tree depth')\n",
        "plt.ylabel('RMSE ($)')\n",
        "plt.title('Bias-Variance: Tree Depth vs RMSE')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig('outputs/bias_variance_analysis.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Best depth by test RMSE\n",
        "best_depth = depths[np.argmin(test_rmse_list)]\n",
        "print(f\"Best tree depth by test RMSE: {best_depth} with RMSE ${min(test_rmse_list):.2f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 6: Learning curve for best model\n",
        "# ---------------------------\n",
        "best_model_name = results_df.iloc[0]['Model']\n",
        "best_model = trained[best_model_name]\n",
        "print(\"Generating learning curve for:\", best_model_name)\n",
        "\n",
        "# Use neg_mean_squared_error scorer then sqrt\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    best_model, X_train_scaled, y_train,\n",
        "    train_sizes=np.linspace(0.1,1.0,10), cv=5, scoring='neg_mean_squared_error', n_jobs=-1\n",
        ")\n",
        "train_rmse_mean = np.sqrt(-train_scores.mean(axis=1))\n",
        "test_rmse_mean = np.sqrt(-test_scores.mean(axis=1))\n",
        "plt.figure()\n",
        "plt.plot(train_sizes, train_rmse_mean, 'o-', label='Train RMSE')\n",
        "plt.plot(train_sizes, test_rmse_mean, 's-', label='Validation RMSE')\n",
        "plt.xlabel('Training size')\n",
        "plt.ylabel('RMSE ($)')\n",
        "plt.title(f'Learning Curve: {best_model_name}')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig('outputs/learning_curve.png', dpi=150)\n",
        "plt.close()\n",
        "print(\"Learning curve saved to outputs/learning_curve.png\")\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 7: Residual analysis for best model\n",
        "# ---------------------------\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_pred, residuals, s=8, alpha=0.5)\n",
        "plt.axhline(0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs Predicted')\n",
        "plt.savefig('outputs/residuals_vs_predicted.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 8: Feature importance (if RF present)\n",
        "# ---------------------------\n",
        "if 'RandomForest_100' in trained:\n",
        "    rf = trained['RandomForest_100']\n",
        "    feat_imp = pd.DataFrame({'feature': X.columns, 'importance': rf.feature_importances_}).sort_values('importance', ascending=False)\n",
        "    feat_imp.head(15).to_csv('outputs/feature_importance_top15.csv', index=False)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    top = feat_imp.head(15)\n",
        "    plt.barh(range(len(top)), top['importance'])\n",
        "    plt.yticks(range(len(top)), top['feature'])\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title('Top 15 Feature Importance (RF)')\n",
        "    plt.savefig('outputs/feature_importance.png', dpi=150)\n",
        "    plt.close()\n",
        "    print(\"Feature importance saved to outputs/feature_importance.png\")\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 9: Underfitting / Overfitting summary\n",
        "# ---------------------------\n",
        "results_df['Error_Gap'] = abs(results_df['Train_RMSE'] - results_df['Test_RMSE'])\n",
        "underfit_threshold = results_df['Test_RMSE'].quantile(0.75)\n",
        "overfit_threshold = results_df['Error_Gap'].quantile(0.75)\n",
        "underfitting = results_df[results_df['Test_RMSE'] > underfit_threshold]\n",
        "overfitting = results_df[results_df['Error_Gap'] > overfit_threshold]\n",
        "\n",
        "print(\"\\nUnderfitting candidates:\\n\", underfitting[['Model','Train_RMSE','Test_RMSE']])\n",
        "print(\"\\nOverfitting candidates:\\n\", overfitting[['Model','Train_RMSE','Test_RMSE','Error_Gap']])\n",
        "\n",
        "# ---------------------------\n",
        "# STEP 10: Real-world issues (print correctly)\n",
        "# ---------------------------\n",
        "real_world_issues = \"\"\"\n",
        "1. OUTLIERS: extreme house prices skew RMSE and may require log-scaling or robust losses.\n",
        "2. NON-LINEARITY: relationships (income vs price) are non-linear; trees/ensembles often perform better.\n",
        "3. SPATIAL AUTOCORRELATION: geographic clustering suggests spatial CV might be better than random split.\n",
        "4. MISSING DATA PATTERNS: simple median imputation used; consider modeling missingness if MNAR.\n",
        "5. DATA AGE: dataset is dated; production models must manage dataset drift.\n",
        "\"\"\"\n",
        "print(real_world_issues)\n",
        "\n",
        "print(\"\\nAll outputs saved under /content/outputs/ - download for inclusion in PDF/GitHub.\")\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1YlGkl27aHz",
        "outputId": "9d3a2f60-38ec-4082-9f9f-eebf90780f4b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CALIFORNIA HOUSING PRICE PREDICTION - REGRESSION ANALYSIS\n",
            "================================================================================\n",
            "Dataset shape: (20640, 10)\n",
            "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0    -122.23     37.88                41.0        880.0           129.0   \n",
            "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
            "2    -122.24     37.85                52.0       1467.0           190.0   \n",
            "\n",
            "   population  households  median_income  median_house_value ocean_proximity  \n",
            "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
            "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
            "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
            "\n",
            "Missing values per column:\n",
            " longitude               0\n",
            "latitude                0\n",
            "housing_median_age      0\n",
            "total_rooms             0\n",
            "total_bedrooms        207\n",
            "population              0\n",
            "households              0\n",
            "median_income           0\n",
            "median_house_value      0\n",
            "ocean_proximity         0\n",
            "dtype: int64\n",
            "\n",
            "Target (median_house_value) stats:\n",
            "count     20640.000000\n",
            "mean     206855.816909\n",
            "std      115395.615874\n",
            "min       14999.000000\n",
            "25%      119600.000000\n",
            "50%      179700.000000\n",
            "75%      264725.000000\n",
            "max      500001.000000\n",
            "Name: median_house_value, dtype: float64\n",
            "EDA plots saved to /content/outputs/\n",
            "Final feature matrix shape: (20640, 13)\n",
            "Training: LinearRegression\n",
            "  Train RMSE: $67987.07, Test RMSE: $74937.02, Test MAE: $52090.72\n",
            "Training: Ridge_a1\n",
            "  Train RMSE: $67987.08, Test RMSE: $74942.91, Test MAE: $52093.15\n",
            "Training: Lasso_a1\n",
            "  Train RMSE: $67987.07, Test RMSE: $74936.20, Test MAE: $52090.49\n",
            "Training: DecisionTree_d5\n",
            "  Train RMSE: $69511.45, Test RMSE: $72649.11, Test MAE: $52231.13\n",
            "Training: DecisionTree_d10\n",
            "  Train RMSE: $47315.45, Test RMSE: $65908.82, Test MAE: $43879.92\n",
            "Training: DecisionTree_full\n",
            "  Train RMSE: $0.00, Test RMSE: $71349.67, Test MAE: $46054.69\n",
            "Training: RandomForest_100\n",
            "  Train RMSE: $41404.85, Test RMSE: $54945.85, Test MAE: $37056.20\n",
            "Training: GradientBoosting\n",
            "  Train RMSE: $41536.52, Test RMSE: $50557.19, Test MAE: $33896.11\n",
            "Model comparison saved to outputs/model_comparison.csv\n",
            "Best tree depth by test RMSE: 9 with RMSE $64539.60\n",
            "Generating learning curve for: GradientBoosting\n",
            "Learning curve saved to outputs/learning_curve.png\n",
            "Feature importance saved to outputs/feature_importance.png\n",
            "\n",
            "Underfitting candidates:\n",
            "               Model    Train_RMSE     Test_RMSE\n",
            "0  LinearRegression  67987.073931  74937.018397\n",
            "1          Ridge_a1  67987.083157  74942.914261\n",
            "\n",
            "Overfitting candidates:\n",
            "                Model    Train_RMSE     Test_RMSE     Error_Gap\n",
            "4   DecisionTree_d10  47315.450628  65908.824269  18593.373641\n",
            "5  DecisionTree_full      0.000000  71349.671628  71349.671628\n",
            "\n",
            "1. OUTLIERS: extreme house prices skew RMSE and may require log-scaling or robust losses.\n",
            "2. NON-LINEARITY: relationships (income vs price) are non-linear; trees/ensembles often perform better.\n",
            "3. SPATIAL AUTOCORRELATION: geographic clustering suggests spatial CV might be better than random split.\n",
            "4. MISSING DATA PATTERNS: simple median imputation used; consider modeling missingness if MNAR.\n",
            "5. DATA AGE: dataset is dated; production models must manage dataset drift.\n",
            "\n",
            "\n",
            "All outputs saved under /content/outputs/ - download for inclusion in PDF/GitHub.\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A — Save best model & scaler\n",
        "import os, joblib\n",
        "\n",
        "# safe defaults if variables missing\n",
        "OUT_DIR = globals().get('OUT_DIR', '/content/outputs')\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "best_model_name = globals().get('best_model_name', None)\n",
        "trained = globals().get('trained', {})\n",
        "\n",
        "if best_model_name is None and len(trained) > 0:\n",
        "    best_model_name = list(trained.keys())[0]\n",
        "\n",
        "if best_model_name in trained:\n",
        "    best_model = trained[best_model_name]\n",
        "    model_path = os.path.join(OUT_DIR, f\"{best_model_name}_model.joblib\")\n",
        "    joblib.dump(best_model, model_path)\n",
        "    print(\"Saved best model to:\", model_path)\n",
        "else:\n",
        "    print(\"Best model not found in session. Available models:\", list(trained.keys()))\n",
        "\n",
        "# Save scaler if present\n",
        "scaler = globals().get('scaler', None)\n",
        "if scaler is not None:\n",
        "    scaler_path = os.path.join(OUT_DIR, \"scaler.joblib\")\n",
        "    joblib.dump(scaler, scaler_path)\n",
        "    print(\"Saved scaler to:\", scaler_path)\n",
        "else:\n",
        "    print(\"No scaler found in session (skipping).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CovbaKj957R",
        "outputId": "149253e7-62a3-4394-8366-4cdd9b6e2f96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best model to: /content/outputs/GradientBoosting_model.joblib\n",
            "Saved scaler to: /content/outputs/scaler.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — Build a one-page PDF summary (fpdf)\n",
        "!pip install -q fpdf\n",
        "\n",
        "from fpdf import FPDF\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "OUT_DIR = globals().get('OUT_DIR', '/content/outputs')\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "results_df = globals().get('results_df', None)\n",
        "df = results_df.copy() if results_df is not None else None\n",
        "\n",
        "# dataset stats\n",
        "df_orig = globals().get('df_raw', None) # Correctly reference the original raw DataFrame\n",
        "count = df_orig.shape[0] if df_orig is not None else 'N/A'\n",
        "mean_target = df_orig['median_house_value'].mean() if df_orig is not None else 'N/A'\n",
        "\n",
        "# prepare top 3 models table\n",
        "top3 = df[['Model','Train_RMSE','Test_RMSE','Test_MAE']].head(3) if df is not None else None\n",
        "\n",
        "# Under/Overfitting note\n",
        "note_lines = [\n",
        "\"Linear models show underfitting (high train & test RMSE).\",\n",
        "\"Full decision tree shows overfitting (near-zero train RMSE, high test RMSE).\",\n",
        "\"Ensembles (RF/GB) balance bias and variance and give best test RMSEs.\",\n",
        "\"Consider spatial CV and robust losses in production to handle outliers & spatial bias.\"\n",
        "]\n",
        "\n",
        "pdf_path = os.path.join(OUT_DIR, 'summary_report.pdf')\n",
        "pdf = FPDF(orientation='P', unit='mm', format='A4')\n",
        "pdf.set_auto_page_break(auto=True, margin=12)\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", 'B', 16)\n",
        "pdf.cell(0, 8, \"California Housing - Module 1 (Q2) Summary\", ln=1, align='C')\n",
        "pdf.ln(2)\n",
        "\n",
        "pdf.set_font(\"Arial\", size=11)\n",
        "pdf.cell(0, 6, f\"Samples: {count}   |   Target mean: ${mean_target:,.2f}\", ln=1)\n",
        "pdf.ln(2)\n",
        "\n",
        "pdf.set_font(\"Arial\", 'B', 12)\n",
        "pdf.cell(0, 6, \"Top 3 Models (by Test RMSE)\", ln=1)\n",
        "pdf.ln(1)\n",
        "\n",
        "pdf.set_font(\"Courier\", size=10)\n",
        "if top3 is not None:\n",
        "    # header\n",
        "    pdf.cell(70,6,\"Model\", border=0)\n",
        "    pdf.cell(40,6,\"Train_RMSE\", border=0)\n",
        "    pdf.cell(40,6,\"Test_RMSE\", border=0)\n",
        "    pdf.cell(30,6,\"Test_MAE\", ln=1, border=0)\n",
        "    for _, row in top3.iterrows():\n",
        "        pdf.cell(70,6,str(row['Model'])[:40], border=0)\n",
        "        pdf.cell(40,6,f\"${row['Train_RMSE']:,.0f}\", border=0)\n",
        "        pdf.cell(40,6,f\"${row['Test_RMSE']:,.0f}\", border=0)\n",
        "        pdf.cell(30,6,f\"${row['Test_MAE']:,.0f}\", ln=1, border=0)\n",
        "else:\n",
        "    pdf.cell(0,6,\"Results table not available.\", ln=1)\n",
        "\n",
        "pdf.ln(4)\n",
        "pdf.set_font(\"Arial\", 'B', 12)\n",
        "pdf.cell(0,6,\"Underfitting / Overfitting Notes\", ln=1)\n",
        "pdf.set_font(\"Arial\", size=11)\n",
        "for l in note_lines:\n",
        "    pdf.multi_cell(0,5,\" - \" + l)\n",
        "pdf.ln(3)\n",
        "\n",
        "pdf.set_font(\"Arial\", 'I', 9)\n",
        "pdf.multi_cell(0,5,\"Outputs saved under /content/outputs/. Figures: EDA, bias-variance plot, learning curve, residuals, feature importance. Use GitHub link in submission.\")\n",
        "pdf.output(pdf_path)\n",
        "print(\"Created PDF summary:\", pdf_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOi_bWxb-B2k",
        "outputId": "064f1412-cc62-46a9-e936-30c151d7bde8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created PDF summary: /content/outputs/summary_report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D — Show download links (Colab)\n",
        "from google.colab import files\n",
        "print(\"You can now download these files:\")\n",
        "for fname in ['house_price_outputs.zip', 'outputs/model_comparison.csv', 'outputs/learning_curve.png', 'outputs/bias_variance_analysis.png', 'outputs/feature_importance.png', 'outputs/residuals_vs_predicted.png', 'outputs/housing_target_dist.png', 'outputs/geographic.png', 'outputs/corr_matrix.png', 'outputs/feature_importance_top15.csv', 'outputs/learning_curve_fast.png', 'outputs/summary_report.pdf']:\n",
        "    if os.path.exists(f\"/content/{fname}\"):\n",
        "        print(\"- /content/\" + fname)\n",
        "    elif os.path.exists(f\"/content/outputs/{os.path.basename(fname)}\"):\n",
        "        path = f\"/content/outputs/{os.path.basename(fname)}\"\n",
        "        print(\"- \" + path)\n",
        "    else:\n",
        "        # some items may be just inside outputs\n",
        "        pass\n",
        "\n",
        "# Optionally trigger direct download for the zip and PDF\n",
        "files.download('/content/house_price_outputs.zip')      # will prompt browser download\n",
        "files.download('/content/outputs/summary_report.pdf')   # will prompt browser download\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "t5sSkiOZBozK",
        "outputId": "f5e80b93-e987-4f30-e7ba-ddc1fb808648"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can now download these files:\n",
            "- /content/house_price_outputs.zip\n",
            "- /content/outputs/model_comparison.csv\n",
            "- /content/outputs/learning_curve.png\n",
            "- /content/outputs/bias_variance_analysis.png\n",
            "- /content/outputs/feature_importance.png\n",
            "- /content/outputs/residuals_vs_predicted.png\n",
            "- /content/outputs/housing_target_dist.png\n",
            "- /content/outputs/geographic.png\n",
            "- /content/outputs/corr_matrix.png\n",
            "- /content/outputs/feature_importance_top15.csv\n",
            "- /content/outputs/summary_report.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0145e04a-78b3-41e8-a4e2-8f267fb05165\", \"house_price_outputs.zip\", 956951)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_232e45d0-9341-48b9-80e8-14094852af50\", \"summary_report.pdf\", 2001)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell E (bash)\n",
        "# (may be slow: installs texlive; skip if not required)\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq texlive-xetex texlive-fonts-recommended texlive-generic-recommended\n",
        "!jupyter nbconvert --to pdf /content/your_notebook.ipynb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGgoZ0neBtCw",
        "outputId": "28451867-27ba-4887-8dcb-ddb37318905a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "E: Unable to locate package texlive-generic-recommended\n",
            "[NbConvertApp] WARNING | pattern '/content/your_notebook.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C — Zip outputs folder\n",
        "import shutil, os\n",
        "OUT_DIR = globals().get('OUT_DIR', '/content/outputs')\n",
        "zip_path = '/content/house_price_outputs.zip'\n",
        "if os.path.exists(zip_path):\n",
        "    os.remove(zip_path)\n",
        "shutil.make_archive('/content/house_price_outputs', 'zip', OUT_DIR)\n",
        "print(\"Created zip:\", zip_path)\n",
        "print(\"Files inside outputs (sample):\")\n",
        "print(sorted(os.listdir(OUT_DIR))[:40])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrxEj8KM-aDm",
        "outputId": "22ec7f81-b6f4-4ace-d265-6a01658e9dbb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created zip: /content/house_price_outputs.zip\n",
            "Files inside outputs (sample):\n",
            "['GradientBoosting_model.joblib', 'bias_variance_analysis.png', 'corr_matrix.png', 'feature_importance.png', 'feature_importance_top15.csv', 'geographic.png', 'housing_target_dist.png', 'learning_curve.png', 'model_comparison.csv', 'residuals_vs_predicted.png', 'scaler.joblib']\n"
          ]
        }
      ]
    }
  ]
}